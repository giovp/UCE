{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e4018ee",
   "metadata": {},
   "source": [
    "# Embedding Novel Species\n",
    "\n",
    "This notebook will create the files you need to embed a novel species that wasn't included in the training data.\n",
    "\n",
    "To start, you will need to download the ESM2 protein embeddings and the reference proteome for the species.\n",
    "\n",
    "You can find precalculated ESM2 protein embeddings for many species [here](https://drive.google.com/drive/folders/1_Dz7HS5N3GoOAG6MdhsXWY1nwLoN13DJ?usp=drive_link)\n",
    "\n",
    "For reference proteomes, you can download them from [here](https://useast.ensembl.org/info/about/species.html).\n",
    "\n",
    "If there is no protein embedding for the species you are interested in, you can request to have it made via Github or email, or you can create it yourself following instructions [here](https://github.com/snap-stanford/SATURN/tree/main/protein_embeddings)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab368d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import torch\n",
    "import scanpy as sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b189335",
   "metadata": {},
   "source": [
    "## Convert ESM2 protien embeddings to UCE format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "75fa0305",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_hdf5(file_path):\n",
    "    \"\"\"Load dictionary from HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to HDF5 file containing embeddings data. The file should have\n",
    "            a 'keys' dataset containing gene names and an 'arrays' group containing the\n",
    "            corresponding embedding arrays.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary mapping gene names (str) to their embedding arrays (numpy.ndarray).\n",
    "            The keys are decoded from bytes to UTF-8 strings.\n",
    "    \"\"\"\n",
    "    data_dict = {}\n",
    "    with h5py.File(file_path, \"r\") as f:\n",
    "        # Get the keys\n",
    "        keys = [k.decode(\"utf-8\") for k in f[\"keys\"][:]]\n",
    "\n",
    "        # Load the arrays\n",
    "        arrays_group = f[\"arrays\"]\n",
    "        for key in keys:\n",
    "            data_dict[key] = arrays_group[str(key)][:]\n",
    "\n",
    "    return data_dict\n",
    "\n",
    "def filter_out_ensembl(PE):\n",
    "    total_before = len(PE.keys())\n",
    "\n",
    "    # Count keys that start with \"ENS\"\n",
    "    ens_count = sum(1 for key in PE.keys() if key.startswith(\"ENS\"))\n",
    "\n",
    "    # Calculate remaining after filtering\n",
    "    remaining = total_before - ens_count\n",
    "\n",
    "    print(f\"Total keys before filtering: {total_before}\")\n",
    "    print(f\"Keys starting with 'ENS' to be filtered: {ens_count}\")\n",
    "    print(f\"Keys remaining after filtering: {remaining}\")\n",
    "\n",
    "    # Remove all key-value pairs that start with \"ENS\"\n",
    "    PE = {k: v for k, v in PE.items() if not k.startswith(\"ENS\")}\n",
    "\n",
    "    return PE\n",
    "\n",
    "def convert_hdf5_to_pt(hdf5_path, output_path):\n",
    "    emb = load_from_hdf5(hdf5_path)\n",
    "    emb_tensors = {k: torch.from_numpy(v) for k, v in emb.items()}\n",
    "\n",
    "    # Filter out ENSP IDs\n",
    "    #emb_tensors = filter_out_ensembl(emb_tensors)\n",
    "\n",
    "    # check dim of first tensor\n",
    "    print(emb_tensors[list(emb_tensors.keys())[0]].shape)\n",
    "    torch.save(emb_tensors, output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c9a306f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIES_NAME = \"lamprey\" # short hand name for this species, will be used in arguments and files\n",
    "H5_FILE_PATH = \"/mnt/czi-sci-ai/generate-cross-species-secondary/protein_embedding_data/pkl/petromyzon_marinus_gene_large.h5\"\n",
    "\n",
    "OUTPUT_DIR = \"/mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280\"\n",
    "\n",
    "MODEL_FILES_PATH = \"/mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280/model_files\"\n",
    "PROTEIN_EMBEDDINGS_PATH = f\"{MODEL_FILES_PATH}/protein_embeddings\"\n",
    "NEW_SPECIES_CSV_PATH = f\"{MODEL_FILES_PATH}/model_files/new_species_protein_embeddings.csv\"\n",
    "\n",
    "# Path to the species proteome\n",
    "SPECIES_PROTEIN_FASTA_PATH = f\"/mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280/fasta/Petromyzon_marinus.Pmarinus_7.0.pep.all.fa\"\n",
    "\n",
    "# Path to the ESM2 Embeddings\n",
    "SPECIES_PROTEIN_EMBEDDINGS_PATH = f\"{PROTEIN_EMBEDDINGS_PATH}/Petromyzon_marinus_ESM2.pt\"\n",
    "\n",
    "# primary_assembly name, this needs to be matched to the FASTA file\n",
    "ASSEMBLY_NAME = \"Pmarinus_7.0\"\n",
    "# NCBI Taxonomy ID, please set this so that if someone else also embeds the same species,\n",
    "# randomly generated chromosome tokens will be the same\n",
    "TAXONOMY_ID = 7757"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dfaec308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5120])\n"
     ]
    }
   ],
   "source": [
    "convert_hdf5_to_pt(H5_FILE_PATH, SPECIES_PROTEIN_EMBEDDINGS_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d37e52",
   "metadata": {},
   "source": [
    "You can view the FASTA format here, please confirm the primary_assembly name is correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ecf1464",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">ENSPMAP00000000001.1 pep scaffold:Pmarinus_7.0:GL476426:6020:9121:-1 gene:ENSPMAG00000000001.1 transcript:ENSPMAT00000000001.1 gene_biotype:protein_coding transcript_biotype:protein_coding gene_symbol:zgc:171772 description:zgc:171772 [Source:ZFIN;Acc:ZDB-GENE-070928-31]\n",
      "MAKRTKKVGIVGKYGTRYGASLRKMVKKIEISQHAKYTCSFCGKTKMKRRAVGIWHCGSC\n",
      "MKTVAGGAWTYNTTSAVTVRSAIRRLRELKDQ\n",
      ">ENSPMAP00000000002.1 pep scaffold:Pmarinus_7.0:GL476426:9753:16206:1 gene:ENSPMAG00000000002.1 transcript:ENSPMAT00000000002.1 gene_biotype:protein_coding transcript_biotype:protein_coding gene_symbol:znf622 description:zinc finger protein 622 [Source:ZFIN;Acc:ZDB-GENE-050927-1]\n",
      "MSAFTCMSCRVAFACADLQRAHYKTDWHRYNLKRKVAQMAPVTAESFAERVLAQRAAAQV\n",
      "PGAVVHQPCATCGKGFASHNAYDNHLRSHRHLQAEARQRDAAQAAHDEVERMNKKNVEKG\n",
      "LEIQPLSKDEMNAAIQQAVFKASPHKSPSLARRRTNPRAWPVGATPPRKPTARQGRRPHP\n",
      "WSSERHRSHPATDEWEDLGTDKDDDDDDWEEEEDDEDEGAVDMELGATTEGAEGAVLSAD\n",
      "GQPAMAGTLPHNGCFFCPQRSRTLARSLAHMSREHGFFIPDVQYLVDLPGLMRYLGEKVG\n",
      "AGNVCLWCNEKGRSFYSLDAVRKHMRDKGHCKLFTDGDAALEFADFYDFRGRDVDGEDEE\n"
     ]
    }
   ],
   "source": [
    "!head {SPECIES_PROTEIN_FASTA_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90540d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "species_to_paths = {\n",
    "    SPECIES_NAME: SPECIES_PROTEIN_FASTA_PATH,\n",
    "}\n",
    "\n",
    "species_to_ids = {\n",
    "    SPECIES_NAME: ASSEMBLY_NAME,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "623b99cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pos_def = []\n",
    "\n",
    "missing_genes = {}\n",
    "for species in species_to_ids.keys():\n",
    "    missing_genes[species] = []\n",
    "    proteome_path = species_to_paths[species]\n",
    "    species_id = species_to_ids[species]\n",
    "\n",
    "    with open(proteome_path) as f:\n",
    "        proteome_lines = f.readlines()\n",
    "\n",
    "    gene_symbol_to_location = {}\n",
    "    gene_symbol_to_chrom = {}\n",
    "\n",
    "    for line in proteome_lines:\n",
    "        if line.startswith(\">\"):\n",
    "            split_line = line.split()\n",
    "            gene_symbol = [token for token in split_line if token.startswith(\"gene_symbol\")]\n",
    "            if len(gene_symbol) > 0:\n",
    "                gene_symbol = gene_symbol[0].split(\":\")\n",
    "                \n",
    "                if len(gene_symbol) == 2:\n",
    "                    gene_symbol = gene_symbol[1]\n",
    "                elif len(gene_symbol) > 2:\n",
    "                    gene_symbol = \":\".join(gene_symbol[1:]) # fix for annoying zebrafish gene names with colons in them\n",
    "                else:\n",
    "                    1/0 # something weird happening, throw an error\n",
    "                \n",
    "                \n",
    "                chrom = None\n",
    "                \n",
    "                chrom_arr = [token for token in split_line if token.startswith(\"chromosome:\")]\n",
    "                if len(chrom_arr) > 0:\n",
    "                    chrom = chrom_arr[0].replace(\"chromosome:\", \"\")\n",
    "                else:\n",
    "                    chrom_arr = [token for token in split_line if token.startswith(\"primary_assembly:\")]\n",
    "                    if len(chrom_arr) > 0:\n",
    "                        chrom = chrom_arr[0].replace(\"primary_assembly:\", \"\")\n",
    "                    else:\n",
    "                        chrom_arr = [token for token in split_line if token.startswith(\"scaffold:\")] \n",
    "                        if len(chrom_arr) > 0:\n",
    "                            chrom = chrom_arr[0].replace(\"scaffold:\", \"\")\n",
    "                if chrom is not None:\n",
    "                    gene_symbol_to_location[gene_symbol] = chrom.split(\":\")[2]\n",
    "                    gene_symbol_to_chrom[gene_symbol] = chrom.split(\":\")[1]\n",
    "                else:\n",
    "                    missing_genes[species].append(gene_symbol)\n",
    "                    \n",
    "\n",
    "    positional_df = pd.DataFrame()\n",
    "    positional_df[\"gene_symbol\"] = [gn.upper() for gn in list(gene_symbol_to_chrom.keys())]\n",
    "    positional_df[\"chromosome\"] = list(gene_symbol_to_chrom.values())\n",
    "    positional_df[\"start\"] = list(gene_symbol_to_location.values())\n",
    "    positional_df = positional_df.sort_values([\"chromosome\", \"start\"])\n",
    "    #positional_df = positional_df.set_index(\"gene_symbol\")\n",
    "    positional_df[\"species\"] = species\n",
    "    all_pos_def.append(positional_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b72887b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gene_symbol</th>\n",
       "      <th>chromosome</th>\n",
       "      <th>start</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3599</th>\n",
       "      <td>KCNJ11</td>\n",
       "      <td>GL476328</td>\n",
       "      <td>1157295</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2930</th>\n",
       "      <td>PTDSS2</td>\n",
       "      <td>GL476328</td>\n",
       "      <td>1205104</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2941</th>\n",
       "      <td>NOSIP</td>\n",
       "      <td>GL476328</td>\n",
       "      <td>1300931</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>RPS4X</td>\n",
       "      <td>GL476328</td>\n",
       "      <td>235293</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>KCNQ1.1</td>\n",
       "      <td>GL476328</td>\n",
       "      <td>385445</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3622</th>\n",
       "      <td>COX1</td>\n",
       "      <td>NC_001626</td>\n",
       "      <td>6610</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3623</th>\n",
       "      <td>COX2</td>\n",
       "      <td>NC_001626</td>\n",
       "      <td>8298</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3624</th>\n",
       "      <td>ATP8</td>\n",
       "      <td>NC_001626</td>\n",
       "      <td>9064</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3625</th>\n",
       "      <td>ATP6</td>\n",
       "      <td>NC_001626</td>\n",
       "      <td>9222</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3626</th>\n",
       "      <td>COX3</td>\n",
       "      <td>NC_001626</td>\n",
       "      <td>9901</td>\n",
       "      <td>lamprey</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3632 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     gene_symbol chromosome    start  species\n",
       "3599      KCNJ11   GL476328  1157295  lamprey\n",
       "2930      PTDSS2   GL476328  1205104  lamprey\n",
       "2941       NOSIP   GL476328  1300931  lamprey\n",
       "2636       RPS4X   GL476328   235293  lamprey\n",
       "2850     KCNQ1.1   GL476328   385445  lamprey\n",
       "...          ...        ...      ...      ...\n",
       "3622        COX1  NC_001626     6610  lamprey\n",
       "3623        COX2  NC_001626     8298  lamprey\n",
       "3624        ATP8  NC_001626     9064  lamprey\n",
       "3625        ATP6  NC_001626     9222  lamprey\n",
       "3626        COX3  NC_001626     9901  lamprey\n",
       "\n",
       "[3632 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_pos_def = pd.concat(all_pos_def)\n",
    "master_pos_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6d9dac28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "lamprey    3632\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "master_pos_def[\"species\"].value_counts() # double check how many genes are mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4a3d45c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lamprey: 0\n"
     ]
    }
   ],
   "source": [
    "for k, v in missing_genes.items():\n",
    "    print(f\"{k}: {len(v)}\") # are any genes missing?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c59774b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n",
      "lamprey\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "chromosome\n",
       "NC_001626    13\n",
       "GL476343     13\n",
       "GL476420     12\n",
       "GL476370     11\n",
       "GL476329     11\n",
       "GL476334     10\n",
       "GL476360     10\n",
       "GL476676      9\n",
       "GL476335      9\n",
       "GL476526      9\n",
       "GL476436      9\n",
       "GL476426      9\n",
       "GL476350      9\n",
       "GL476535      8\n",
       "GL476614      8\n",
       "GL476950      8\n",
       "GL476962      8\n",
       "GL476330      8\n",
       "GL501311      8\n",
       "GL476358      8\n",
       "GL476337      7\n",
       "GL476592      7\n",
       "GL476932      7\n",
       "GL501318      7\n",
       "GL476508      7\n",
       "GL477257      7\n",
       "GL476366      7\n",
       "GL478697      7\n",
       "GL476616      6\n",
       "GL476598      6\n",
       "GL476390      6\n",
       "GL476392      6\n",
       "GL476396      6\n",
       "GL476397      6\n",
       "GL476437      6\n",
       "GL476416      6\n",
       "GL476446      6\n",
       "GL476399      6\n",
       "GL476356      6\n",
       "GL476414      6\n",
       "GL476493      6\n",
       "GL476557      6\n",
       "GL478317      6\n",
       "GL476328      6\n",
       "GL477107      6\n",
       "GL477001      6\n",
       "GL476376      6\n",
       "GL477040      6\n",
       "GL478223      5\n",
       "GL477670      5\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*********\n"
     ]
    }
   ],
   "source": [
    "# Count genes per chromosome\n",
    "for species in species_to_ids.keys():\n",
    "    print(\"*********\")\n",
    "    print(species)\n",
    "    display(master_pos_def[master_pos_def[\"species\"] == species][\"chromosome\"].value_counts().head(50))\n",
    "    print(\"*********\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694d4001",
   "metadata": {},
   "source": [
    "## Filter ESM2 embeddings to only include genes in the master_pos_def\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8331053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10509/1721332365.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  PE = torch.load(SPECIES_PROTEIN_EMBEDDINGS_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of genes in PE before filtering: 10292\n",
      "Number of genes in PE after filtering: 3618\n",
      "Number of genes in master_pos_def after filtering: 3618\n"
     ]
    }
   ],
   "source": [
    "PE = torch.load(SPECIES_PROTEIN_EMBEDDINGS_PATH)\n",
    "print(f\"Number of genes in PE before filtering: {len(PE)}\")\n",
    "# Find intersection of gene symbols between PE and master_pos_def\n",
    "pe_genes = {k.upper() for k in PE.keys()}\n",
    "master_genes = set(master_pos_def[\"gene_symbol\"].unique())\n",
    "common_genes = pe_genes & master_genes\n",
    "# Filter both PE and master_pos_def to only include common genes\n",
    "PE = {k.upper(): v for k, v in PE.items() if k.upper() in common_genes}\n",
    "print(f\"Number of genes in PE after filtering: {len(PE)}\")\n",
    "master_pos_def = master_pos_def[master_pos_def[\"gene_symbol\"].isin(common_genes)]\n",
    "# Keep only first occurrence of each gene symbol to ensure uniqueness\n",
    "master_pos_def = master_pos_def.drop_duplicates(subset=['gene_symbol'], keep='first')\n",
    "\n",
    "print(f\"Number of genes in master_pos_def after filtering: {len(master_pos_def)}\")\n",
    "\n",
    "if len(PE) != len(master_pos_def[\"gene_symbol\"].unique()):\n",
    "    print(f\"Number of genes in PE: {len(PE)}\")\n",
    "    print(f\"Number of genes in master_pos_def: {len(master_pos_def['gene_symbol'].unique())}\")\n",
    "    raise ValueError(\"Number of genes in PE and master_pos_def are not the same\")\n",
    "\n",
    "FILTERED_SPECIES_PROTEIN_EMBEDDINGS_PATH = SPECIES_PROTEIN_EMBEDDINGS_PATH[:-4] + \"_filtered.pt\"\n",
    "torch.save(PE, FILTERED_SPECIES_PROTEIN_EMBEDDINGS_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "541baded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280/lamprey_to_chrom_pos.csv\n"
     ]
    }
   ],
   "source": [
    "chrom_file = f\"{OUTPUT_DIR}/{SPECIES_NAME}_to_chrom_pos.csv\"\n",
    "master_pos_def.to_csv(chrom_file, index=False) # Save the DF\n",
    "# The chromosome file path will be:\n",
    "print(chrom_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e277f",
   "metadata": {},
   "source": [
    "# Generate token file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2798848",
   "metadata": {},
   "source": [
    "This will create the token file. Please note the offset value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4355dabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_10509/3083231355.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  all_pe = torch.load(\"/mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280/all_tokens.torch\")[0:4] # read in existing token file to make sure\n",
      "/tmp/ipykernel_10509/3083231355.py:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  PE = torch.load(FILTERED_SPECIES_PROTEIN_EMBEDDINGS_PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHROM_TOKEN_OFFSET: 3622\n",
      "Saving PE tokens to /mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280/lamprey_pe_tokens.torch\n",
      "Saving offsets to /mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280/lamprey_offsets.pkl\n",
      "Saved PE, offsets file\n"
     ]
    }
   ],
   "source": [
    "token_dim = 5120\n",
    "species_to_offsets = {}\n",
    "\n",
    "N_UNIQ_CHROM = len(master_pos_def[master_pos_def[\"species\"] == species][\"chromosome\"].unique())\n",
    "\n",
    "all_pe = torch.load(\"/mnt/czi-sci-ai/generate-cross-species-secondary/eval/baselines/uce/33l_8ep_1024t_1280/all_tokens.torch\")[0:4] # read in existing token file to make sure \n",
    "# that special vocab tokens are the same for different seeds\n",
    "\n",
    "offset = len(all_pe) # special tokens at the top!\n",
    "\n",
    "PE = torch.load(FILTERED_SPECIES_PROTEIN_EMBEDDINGS_PATH)\n",
    "\n",
    "pe_stacked = torch.stack(list(PE.values()))\n",
    "all_pe = torch.vstack((all_pe, pe_stacked))\n",
    "species_to_offsets[species] = offset\n",
    "\n",
    "CHROM_TOKEN_OFFSET = all_pe.shape[0]\n",
    "print(\"CHROM_TOKEN_OFFSET:\", CHROM_TOKEN_OFFSET)\n",
    "torch.manual_seed(TAXONOMY_ID)\n",
    "CHROM_TENSORS = torch.normal(mean=0, std=1, size=(N_UNIQ_CHROM, 5120)) \n",
    "# N_UNIQ_CHROM is the total number of chromosome choices, it is hardcoded for now (for species in the training data)\n",
    "all_pe = torch.vstack(\n",
    "    (all_pe, CHROM_TENSORS))  # Add the chrom tensors to the end\n",
    "all_pe.requires_grad = False\n",
    "\n",
    "assert all_pe.size(0) == master_pos_def.shape[0] + 4 + N_UNIQ_CHROM, f\"all_pe.size(0): {all_pe.size(0)}, master_pos_def.shape[0]: {master_pos_def.shape[0]}, N_UNIQ_CHROM: {N_UNIQ_CHROM}\"\n",
    "\n",
    "pe_tokens_file = f\"{OUTPUT_DIR}/{SPECIES_NAME}_pe_tokens.torch\"\n",
    "print(f\"Saving PE tokens to {pe_tokens_file}\")\n",
    "torch.save(all_pe, pe_tokens_file)\n",
    "\n",
    "offsets_file = f\"{OUTPUT_DIR}/{SPECIES_NAME}_offsets.pkl\"\n",
    "print(f\"Saving offsets to {offsets_file}\")\n",
    "with open(offsets_file, \"wb+\") as f:\n",
    "    pickle.dump(species_to_offsets, f)\n",
    "print(\"Saved PE, offsets file\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aed61cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2396"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_UNIQ_CHROM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "709c20bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lamprey': 4}\n"
     ]
    }
   ],
   "source": [
    "with open(offsets_file, \"rb\") as f:\n",
    "    offsets = pickle.load(f)\n",
    "print(offsets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c6bca2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated /mnt/czi-sci-ai/generate-cross-species-secondary/jpearce/scg-baselines/models/uce/model_files/new_species_protein_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load existing CSV or create new one if it doesn't exist\n",
    "try:\n",
    "    embeddings_df = pd.read_csv(NEW_SPECIES_CSV_PATH)\n",
    "except FileNotFoundError:\n",
    "    embeddings_df = pd.DataFrame(columns=['species', 'path', 'chrom_token_offset'])\n",
    "\n",
    "# Add new row\n",
    "new_row = pd.DataFrame({\n",
    "    'species': [SPECIES_NAME],\n",
    "    'path': [FILTERED_SPECIES_PROTEIN_EMBEDDINGS_PATH],\n",
    "    'chrom_token_offset': [CHROM_TOKEN_OFFSET]\n",
    "})\n",
    "\n",
    "# Combine and remove duplicates based on species\n",
    "embeddings_df = pd.concat([embeddings_df, new_row])\n",
    "embeddings_df = embeddings_df.drop_duplicates(subset=['species'], keep='last')\n",
    "\n",
    "# Save updated CSV\n",
    "embeddings_df.to_csv(NEW_SPECIES_CSV_PATH, index=False)\n",
    "print(f\"Updated {NEW_SPECIES_CSV_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4697330",
   "metadata": {},
   "source": [
    "# Example evaluation of new species"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b72667d",
   "metadata": {},
   "source": [
    "**Note: when you evaluate a new species, you need to change some arguments and modify some files:**\n",
    "\n",
    "You will  need to modify the csv in `model_files/new_species_protein_embeddings.csv` to include the new protein embeddings file you downloaded.\n",
    "\n",
    "In the file add a row for the new species with the format:\n",
    "`species name,full path to protein embedding file`\n",
    "\n",
    "Please also add this line to the dictionary created on line 247 in the file `data_proc/data_utils.py`.\n",
    "\n",
    "When you want to embed this new species, you will need to specify these newly created files as arguments.\n",
    "- `CHROM_TOKEN_OFFSET`: This tells UCE when the rows corresponding to chromosome tokens starts.\n",
    "- `spec_chrom_csv_path`: This is a new csv, created by this script, which maps genes to chromosomes and genomic positions\n",
    "- `token_file`: This is a new token file that will work just for this species. The embeddings generated will still be universal though!\n",
    "- `offset_pkl_path`: This is another file that maps genes to tokens\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "accelerate launch eval_single_anndata.py chicken_heart.h5ad --species=chicken --CHROM_TOKEN_OFFSET=13275 --spec_chrom_csv_path=data_proc/chicken_to_chrom_pos.csv --token_file=data_proc/chicken_pe_tokens.torch --offset_pkl_path=data_proc/chicken_offsets.pkl --dir=... --multi_gpu=True\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb39ce8b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f19bff55",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
